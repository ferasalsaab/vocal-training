{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.contrib.keras import models\n",
    "from tensorflow.contrib.keras import layers\n",
    "from tensorflow.contrib import keras\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "plt.rcParams['font.family'] = 'serif'\n",
    "plt.rcParams['font.serif'] = 'Ubuntu'\n",
    "plt.rcParams['font.monospace'] = 'Ubuntu Mono'\n",
    "plt.rcParams['font.size'] = 12\n",
    "plt.rcParams['axes.labelsize'] = 11\n",
    "plt.rcParams['axes.labelweight'] = 'bold'\n",
    "plt.rcParams['axes.titlesize'] = 12\n",
    "plt.rcParams['xtick.labelsize'] = 9\n",
    "plt.rcParams['ytick.labelsize'] = 9\n",
    "plt.rcParams['legend.fontsize'] = 11\n",
    "plt.rcParams['figure.titlesize'] = 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def windows(data, window_size):\n",
    "    start = 0\n",
    "    while start < len(data):\n",
    "        yield int(start), int(start + window_size)\n",
    "        start += (window_size / 2)\n",
    "\n",
    "def extract_features(parent_dir,sub_dirs,file_ext=\"*.wav\",bands = 60, frames = 41):\n",
    "    window_size = 512 * (frames - 1)\n",
    "    log_specgrams = []\n",
    "    labels = []\n",
    "    for l, sub_dir in enumerate(sub_dirs):\n",
    "        for fn in glob.glob(os.path.join(parent_dir, sub_dir, file_ext)):\n",
    "            sound_clip,s = librosa.load(fn)\n",
    "            label = fn.split('/')[-1].split('-')[1]\n",
    "            for (start,end) in windows(sound_clip,window_size):\n",
    "                if(len(sound_clip[start:end]) == window_size):\n",
    "                    signal = sound_clip[start:end]\n",
    "                    melspec = librosa.feature.melspectrogram(signal, n_mels = bands)\n",
    "                    logspec = librosa.logamplitude(melspec)\n",
    "                    logspec = logspec.T.flatten()[:, np.newaxis].T\n",
    "                    log_specgrams.append(logspec)\n",
    "                    labels.append(label)\n",
    "            \n",
    "    log_specgrams = np.asarray(log_specgrams).reshape(len(log_specgrams),bands,frames,1)\n",
    "    features = np.concatenate((log_specgrams, np.zeros(np.shape(log_specgrams))), axis = 3)\n",
    "    for i in range(len(features)):\n",
    "        features[i, :, :, 1] = librosa.feature.delta(features[i, :, :, 0])\n",
    "    \n",
    "    return np.array(features), np.array(labels,dtype = np.int) \n",
    "\n",
    "def one_hot_encode(labels):\n",
    "    n_labels = len(labels)\n",
    "    n_unique_labels = len(np.unique(labels))\n",
    "    one_hot_encode = np.zeros((n_labels,n_unique_labels))\n",
    "    one_hot_encode[np.arange(n_labels), labels] = 1\n",
    "    return one_hot_encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_single_file_feature(fn, fn2, bands = 25, frames = 41):\n",
    "    window_size = 512 * (frames - 1)\n",
    "    log_specgrams = []\n",
    "    labels = []\n",
    "    sound_clip,s = librosa.load(fn)\n",
    "    label = os.path.basename(os.path.splitext(fn)[0])\n",
    "    count = 1\n",
    "    for (start,end) in windows(sound_clip,window_size):\n",
    "        if(len(sound_clip[start:end]) == window_size):\n",
    "            print('\\nwindow %d shapes:'%count)\n",
    "            signal = sound_clip[start:end]\n",
    "            melspec = librosa.feature.melspectrogram(signal, n_mels = bands)\n",
    "            print('melspec.shape - %s'%str(melspec.shape))\n",
    "            logspec = librosa.logamplitude(melspec)\n",
    "            print('logspec.shape - %s'%str(logspec.shape))\n",
    "            logspec = logspec.T.flatten()[:, np.newaxis].T\n",
    "            print('logspec.shape - %s'%str(logspec.shape))\n",
    "            log_specgrams.append(logspec)\n",
    "            labels.append(label)\n",
    "            count = count + 1\n",
    "            \n",
    "    sound_clip,s = librosa.load(fn2)\n",
    "    label = os.path.basename(os.path.splitext(fn2)[0])\n",
    "    count = 1\n",
    "    for (start,end) in windows(sound_clip,window_size):\n",
    "        if(len(sound_clip[start:end]) == window_size):\n",
    "            print('\\nwindow %d shapes:'%count)\n",
    "            signal = sound_clip[start:end]\n",
    "            melspec = librosa.feature.melspectrogram(signal, n_mels = bands)\n",
    "            print('melspec.shape - %s'%str(melspec.shape))\n",
    "            logspec = librosa.logamplitude(melspec)\n",
    "            print('logspec.shape - %s'%str(logspec.shape))\n",
    "            logspec = logspec.T.flatten()[:, np.newaxis].T\n",
    "            print('logspec.shape - %s'%str(logspec.shape))\n",
    "            log_specgrams.append(logspec)\n",
    "            labels.append(label)\n",
    "            count = count + 1\n",
    "\n",
    "\n",
    "    log_specgrams = np.asarray(log_specgrams).reshape(len(log_specgrams),bands,frames,1)\n",
    "    print('\\nlog_specgrams.shape - %s'%str(log_specgrams.shape))\n",
    "    features = np.concatenate((log_specgrams, np.zeros(np.shape(log_specgrams))), axis = 3)\n",
    "    print('features.shape - %s'%str(features.shape))\n",
    "    print('len of features = %s'%str(len(features)))\n",
    "    for i in range(len(features)):\n",
    "        features[i, :, :, 1] = librosa.feature.delta(features[i, :, :, 0])\n",
    "    print('features.shape - %s'%str(features.shape))\n",
    "    return np.array(features), np.array(labels,dtype = np.int) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "window 1 shapes:\n",
      "melspec.shape - (25, 41)\n",
      "logspec.shape - (25, 41)\n",
      "logspec.shape - (1, 1025)\n",
      "\n",
      "window 2 shapes:\n",
      "melspec.shape - (25, 41)\n",
      "logspec.shape - (25, 41)\n",
      "logspec.shape - (1, 1025)\n",
      "\n",
      "window 3 shapes:\n",
      "melspec.shape - (25, 41)\n",
      "logspec.shape - (25, 41)\n",
      "logspec.shape - (1, 1025)\n",
      "\n",
      "window 4 shapes:\n",
      "melspec.shape - (25, 41)\n",
      "logspec.shape - (25, 41)\n",
      "logspec.shape - (1, 1025)\n",
      "\n",
      "window 5 shapes:\n",
      "melspec.shape - (25, 41)\n",
      "logspec.shape - (25, 41)\n",
      "logspec.shape - (1, 1025)\n",
      "\n",
      "window 1 shapes:\n",
      "melspec.shape - (25, 41)\n",
      "logspec.shape - (25, 41)\n",
      "logspec.shape - (1, 1025)\n",
      "\n",
      "window 2 shapes:\n",
      "melspec.shape - (25, 41)\n",
      "logspec.shape - (25, 41)\n",
      "logspec.shape - (1, 1025)\n",
      "\n",
      "window 3 shapes:\n",
      "melspec.shape - (25, 41)\n",
      "logspec.shape - (25, 41)\n",
      "logspec.shape - (1, 1025)\n",
      "\n",
      "window 4 shapes:\n",
      "melspec.shape - (25, 41)\n",
      "logspec.shape - (25, 41)\n",
      "logspec.shape - (1, 1025)\n",
      "\n",
      "window 5 shapes:\n",
      "melspec.shape - (25, 41)\n",
      "logspec.shape - (25, 41)\n",
      "logspec.shape - (1, 1025)\n",
      "\n",
      "log_specgrams.shape - (10, 25, 41, 1)\n",
      "features.shape - (10, 25, 41, 2)\n",
      "len of features = 10\n",
      "features.shape - (10, 25, 41, 2)\n"
     ]
    }
   ],
   "source": [
    "ft, lb = extract_single_file_feature('/Users/Gundeep/Dropbox/notebook/sounds/recorded/large/ah_drakht_boht_sohna_lag_reha/1.wav','/Users/Gundeep/Dropbox/notebook/sounds/recorded/large/ah_drakht_boht_sohna_lag_reha/3.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 3, 3, 3, 3, 3])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parent_dir = '/home/paperspace/Documents/Projects/Urban Sound Classification/UrbanSound8K/audio/'\n",
    "sub_dirs= ['fold1','fold2']\n",
    "features,labels = extract_features(parent_dir,sub_dirs)\n",
    "labels = one_hot_encode(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dump to pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rnd_indices = np.random.rand(len(labels)) < 0.70\n",
    "\n",
    "train_x = features[rnd_indices]\n",
    "train_y = labels[rnd_indices]\n",
    "test_x = features[~rnd_indices]\n",
    "test_y = labels[~rnd_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# dump to pickle\n",
    "if os.environ['HOME'] == '/Users/Gundeep':\n",
    "    pickle_filename = 'urban_pickle_cnn.pickle'\n",
    "else:\n",
    "    pickle_filename = '/home/paperspace/Documents/Projects/Urban Sound Classification/urban_pickle_cnn.pickle'\n",
    "\n",
    "pickle_dump = {'train_x' : train_x,\n",
    "               'train_y' : train_y,\n",
    "               'test_x' : test_x,\n",
    "               'test_y' : test_y}\n",
    "import pickle\n",
    "try:\n",
    "  with open(pickle_filename, 'wb') as f:\n",
    "    pickle.dump(pickle_dump, f, pickle.HIGHEST_PROTOCOL)\n",
    "except Exception as e:\n",
    "  print('Unable to save data to', pickle_filename, ':', e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load from pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load from pickle\n",
    "import pickle\n",
    "if os.environ['HOME'] == '/Users/Gundeep':\n",
    "    pickle_filename = 'urban_pickle_cnn.pickle'\n",
    "else:\n",
    "    pickle_filename = '/home/paperspace/Documents/Projects/Urban Sound Classification/urban_pickle_cnn.pickle'\n",
    "pickle_dump = {}\n",
    "try:\n",
    "  with open(pickle_filename, 'rb') as f:\n",
    "    pickle_dump = pickle.load(f)\n",
    "except Exception as e:\n",
    "  print('Unable to load pickle', pickle_filename, ':', e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_x = pickle_dump['train_x']\n",
    "train_y = pickle_dump['train_y']\n",
    "test_x = pickle_dump['test_x']\n",
    "test_y = pickle_dump['test_y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_x:(7594, 60, 41, 2)\n",
      "train_y(7594, 10)\n",
      "test_x(3240, 60, 41, 2)\n",
      "test_y:(3240, 10)\n"
     ]
    }
   ],
   "source": [
    "print('train_x:%s'%str(train_x.shape))\n",
    "print('train_y%s'%str(train_y.shape))\n",
    "print('test_x%s'%str(test_x.shape))\n",
    "print('test_y:%s'%str(test_y.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create neural net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# keras class shorthands\n",
    "Sequential = models.Sequential\n",
    "Dense = layers.Dense\n",
    "Conv2D = layers.Conv2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "frames = 41\n",
    "bands = 60\n",
    "\n",
    "feature_size = 2460 #60x41\n",
    "num_classes = 10\n",
    "num_channels = 2\n",
    "epochs = 2000\n",
    "\n",
    "batch_size = 50\n",
    "kernel_size = 30\n",
    "depth = 20\n",
    "num_hidden = 200\n",
    "\n",
    "learning_rate = 0.01\n",
    "training_iterations = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60, 41, 2)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(depth, (5,5), input_shape=train_x.shape[1:], activation='relu', padding='same'))\n",
    "model.add(layers.Flatten())\n",
    "model.add(Dense(num_hidden, activation='sigmoid'))\n",
    "model.add(Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "opt = keras.optimizers.Adam(lr=learning_rate)#, decay=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### setup file logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import CSVLogger\n",
    "csv_logger = CSVLogger('/home/paperspace/Documents/log.csv', append=True, separator=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7594 samples, validate on 3240 samples\n",
      "Epoch 1/2000\n",
      "7594/7594 [==============================] - 5s - loss: 2.2292 - acc: 0.1625 - val_loss: 2.2812 - val_acc: 0.1654\n",
      "Epoch 2/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1836 - acc: 0.1836 - val_loss: 2.1100 - val_acc: 0.1960\n",
      "Epoch 3/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1898 - acc: 0.1603 - val_loss: 2.2531 - val_acc: 0.1642\n",
      "Epoch 4/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1942 - acc: 0.1628 - val_loss: 2.1620 - val_acc: 0.1667\n",
      "Epoch 5/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1584 - acc: 0.1707 - val_loss: 2.1555 - val_acc: 0.1741\n",
      "Epoch 6/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1404 - acc: 0.1809 - val_loss: 2.3227 - val_acc: 0.2022\n",
      "Epoch 7/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1499 - acc: 0.1882 - val_loss: 2.0639 - val_acc: 0.2191\n",
      "Epoch 8/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.0972 - acc: 0.2133 - val_loss: 2.1332 - val_acc: 0.2389\n",
      "Epoch 9/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.0567 - acc: 0.2266 - val_loss: 2.0784 - val_acc: 0.1784\n",
      "Epoch 10/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1001 - acc: 0.2096 - val_loss: 2.1260 - val_acc: 0.1938\n",
      "Epoch 11/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1576 - acc: 0.1799 - val_loss: 2.1700 - val_acc: 0.1762\n",
      "Epoch 12/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.2000 - acc: 0.1616 - val_loss: 2.2836 - val_acc: 0.1836\n",
      "Epoch 13/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1831 - acc: 0.1568 - val_loss: 2.1994 - val_acc: 0.1759\n",
      "Epoch 14/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1788 - acc: 0.1592 - val_loss: 2.1495 - val_acc: 0.1756\n",
      "Epoch 15/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1791 - acc: 0.1655 - val_loss: 2.2431 - val_acc: 0.1608\n",
      "Epoch 16/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1794 - acc: 0.1667 - val_loss: 2.1679 - val_acc: 0.1491\n",
      "Epoch 17/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1731 - acc: 0.1628 - val_loss: 2.2143 - val_acc: 0.1691\n",
      "Epoch 18/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1714 - acc: 0.1642 - val_loss: 2.1746 - val_acc: 0.1608\n",
      "Epoch 19/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1667 - acc: 0.1593 - val_loss: 2.2342 - val_acc: 0.1596\n",
      "Epoch 20/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1650 - acc: 0.1578 - val_loss: 2.1617 - val_acc: 0.1840\n",
      "Epoch 21/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1624 - acc: 0.1671 - val_loss: 2.1483 - val_acc: 0.1639\n",
      "Epoch 22/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1926 - acc: 0.1621 - val_loss: 2.1586 - val_acc: 0.1818\n",
      "Epoch 23/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1725 - acc: 0.1578 - val_loss: 2.1899 - val_acc: 0.1478\n",
      "Epoch 24/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1700 - acc: 0.1642 - val_loss: 2.1753 - val_acc: 0.1799\n",
      "Epoch 25/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1708 - acc: 0.1628 - val_loss: 2.1730 - val_acc: 0.1775\n",
      "Epoch 26/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1534 - acc: 0.1633 - val_loss: 2.1480 - val_acc: 0.1494\n",
      "Epoch 27/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1525 - acc: 0.1567 - val_loss: 2.1684 - val_acc: 0.1420\n",
      "Epoch 28/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1816 - acc: 0.1601 - val_loss: 2.1605 - val_acc: 0.1775\n",
      "Epoch 29/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1601 - acc: 0.1600 - val_loss: 2.2143 - val_acc: 0.1815\n",
      "Epoch 30/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1643 - acc: 0.1633 - val_loss: 2.1796 - val_acc: 0.1488\n",
      "Epoch 31/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1654 - acc: 0.1604 - val_loss: 2.2040 - val_acc: 0.16850.1\n",
      "Epoch 32/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.2102 - acc: 0.1658 - val_loss: 2.2263 - val_acc: 0.1673\n",
      "Epoch 33/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1879 - acc: 0.1558 - val_loss: 2.1856 - val_acc: 0.1639\n",
      "Epoch 34/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1978 - acc: 0.1597 - val_loss: 2.1532 - val_acc: 0.1920\n",
      "Epoch 35/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1831 - acc: 0.1620 - val_loss: 2.2692 - val_acc: 0.1472\n",
      "Epoch 36/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1848 - acc: 0.1658 - val_loss: 2.1409 - val_acc: 0.1562\n",
      "Epoch 37/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1599 - acc: 0.1671 - val_loss: 2.1536 - val_acc: 0.1910\n",
      "Epoch 38/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1776 - acc: 0.1711 - val_loss: 2.1805 - val_acc: 0.1460\n",
      "Epoch 39/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1612 - acc: 0.1603 - val_loss: 2.2049 - val_acc: 0.1731\n",
      "Epoch 40/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1808 - acc: 0.1608 - val_loss: 2.1505 - val_acc: 0.1914\n",
      "Epoch 41/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1562 - acc: 0.1732 - val_loss: 2.1478 - val_acc: 0.1846\n",
      "Epoch 42/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1561 - acc: 0.1632 - val_loss: 2.1647 - val_acc: 0.1472\n",
      "Epoch 43/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1570 - acc: 0.1740 - val_loss: 2.1928 - val_acc: 0.1873\n",
      "Epoch 44/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1432 - acc: 0.1668 - val_loss: 2.2226 - val_acc: 0.1398\n",
      "Epoch 45/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1607 - acc: 0.1695 - val_loss: 2.1137 - val_acc: 0.1914\n",
      "Epoch 46/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1468 - acc: 0.1712 - val_loss: 2.1272 - val_acc: 0.1731\n",
      "Epoch 47/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1437 - acc: 0.1696 - val_loss: 2.2363 - val_acc: 0.1901\n",
      "Epoch 48/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1577 - acc: 0.1646 - val_loss: 2.1946 - val_acc: 0.1469\n",
      "Epoch 49/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1626 - acc: 0.1708 - val_loss: 2.1812 - val_acc: 0.1787\n",
      "Epoch 50/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1528 - acc: 0.1659 - val_loss: 2.1191 - val_acc: 0.1735\n",
      "Epoch 51/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1441 - acc: 0.1708 - val_loss: 2.2024 - val_acc: 0.1849\n",
      "Epoch 52/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1496 - acc: 0.1797 - val_loss: 2.1707 - val_acc: 0.1559\n",
      "Epoch 53/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1667 - acc: 0.1699 - val_loss: 2.1207 - val_acc: 0.1744\n",
      "Epoch 54/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1738 - acc: 0.1647 - val_loss: 2.2436 - val_acc: 0.1639\n",
      "Epoch 55/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1569 - acc: 0.1774 - val_loss: 2.1154 - val_acc: 0.1556\n",
      "Epoch 56/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1489 - acc: 0.1729 - val_loss: 2.1485 - val_acc: 0.1648\n",
      "Epoch 57/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1643 - acc: 0.1659 - val_loss: 2.1633 - val_acc: 0.1506\n",
      "Epoch 58/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1710 - acc: 0.1704 - val_loss: 2.1259 - val_acc: 0.1787\n",
      "Epoch 59/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1612 - acc: 0.1696 - val_loss: 2.1859 - val_acc: 0.1664\n",
      "Epoch 60/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1717 - acc: 0.1705 - val_loss: 2.1644 - val_acc: 0.1559\n",
      "Epoch 61/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1578 - acc: 0.1653 - val_loss: 2.2071 - val_acc: 0.1867\n",
      "Epoch 62/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1523 - acc: 0.1696 - val_loss: 2.1980 - val_acc: 0.1846\n",
      "Epoch 63/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1676 - acc: 0.1740 - val_loss: 2.2543 - val_acc: 0.1556\n",
      "Epoch 64/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7594/7594 [==============================] - 3s - loss: 2.1714 - acc: 0.1749 - val_loss: 2.1553 - val_acc: 0.1861\n",
      "Epoch 65/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1612 - acc: 0.1716 - val_loss: 2.1526 - val_acc: 0.1556\n",
      "Epoch 66/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1637 - acc: 0.1676 - val_loss: 2.1462 - val_acc: 0.17310.1\n",
      "Epoch 67/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1568 - acc: 0.1653 - val_loss: 2.1636 - val_acc: 0.1738\n",
      "Epoch 68/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1475 - acc: 0.1741 - val_loss: 2.2242 - val_acc: 0.1833\n",
      "Epoch 69/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1615 - acc: 0.1662 - val_loss: 2.1816 - val_acc: 0.1867\n",
      "Epoch 70/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1818 - acc: 0.1692 - val_loss: 2.2366 - val_acc: 0.1914\n",
      "Epoch 71/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1390 - acc: 0.1790 - val_loss: 2.1013 - val_acc: 0.1910\n",
      "Epoch 72/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1491 - acc: 0.1614 - val_loss: 2.2357 - val_acc: 0.1861\n",
      "Epoch 73/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1514 - acc: 0.1728 - val_loss: 2.2123 - val_acc: 0.13920\n",
      "Epoch 74/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1579 - acc: 0.1697 - val_loss: 2.2249 - val_acc: 0.1651\n",
      "Epoch 75/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1594 - acc: 0.1711 - val_loss: 2.1416 - val_acc: 0.1867\n",
      "Epoch 76/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1565 - acc: 0.1699 - val_loss: 2.1448 - val_acc: 0.1556\n",
      "Epoch 77/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1498 - acc: 0.1750 - val_loss: 2.1405 - val_acc: 0.1475\n",
      "Epoch 78/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1625 - acc: 0.1691 - val_loss: 2.1795 - val_acc: 0.1509\n",
      "Epoch 79/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1536 - acc: 0.1647 - val_loss: 2.1263 - val_acc: 0.1907\n",
      "Epoch 80/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1407 - acc: 0.1705 - val_loss: 2.1256 - val_acc: 0.1907\n",
      "Epoch 81/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1343 - acc: 0.1783 - val_loss: 2.2167 - val_acc: 0.1481\n",
      "Epoch 82/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1464 - acc: 0.1750 - val_loss: 2.1260 - val_acc: 0.1728\n",
      "Epoch 83/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1525 - acc: 0.1621 - val_loss: 2.2263 - val_acc: 0.1559\n",
      "Epoch 84/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1642 - acc: 0.1676 - val_loss: 2.1614 - val_acc: 0.1907\n",
      "Epoch 85/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1576 - acc: 0.1729 - val_loss: 2.1952 - val_acc: 0.1784\n",
      "Epoch 86/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1551 - acc: 0.1667 - val_loss: 2.2282 - val_acc: 0.1642\n",
      "Epoch 87/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1418 - acc: 0.1701 - val_loss: 2.1270 - val_acc: 0.1648\n",
      "Epoch 88/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1465 - acc: 0.1716 - val_loss: 2.2327 - val_acc: 0.1648\n",
      "Epoch 89/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1631 - acc: 0.1700 - val_loss: 2.1499 - val_acc: 0.1642\n",
      "Epoch 90/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1475 - acc: 0.1724 - val_loss: 2.1178 - val_acc: 0.1509\n",
      "Epoch 91/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1566 - acc: 0.1655 - val_loss: 2.1747 - val_acc: 0.1556\n",
      "Epoch 92/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1383 - acc: 0.1715 - val_loss: 2.1118 - val_acc: 0.1722\n",
      "Epoch 93/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1564 - acc: 0.1682 - val_loss: 2.1567 - val_acc: 0.1920\n",
      "Epoch 94/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1610 - acc: 0.1682 - val_loss: 2.1450 - val_acc: 0.1914\n",
      "Epoch 95/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1460 - acc: 0.1686 - val_loss: 2.1481 - val_acc: 0.1858\n",
      "Epoch 96/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1434 - acc: 0.1680 - val_loss: 2.1739 - val_acc: 0.1556\n",
      "Epoch 97/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1705 - acc: 0.1639 - val_loss: 2.1159 - val_acc: 0.1772\n",
      "Epoch 98/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1600 - acc: 0.1776 - val_loss: 2.1442 - val_acc: 0.1725\n",
      "Epoch 99/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1439 - acc: 0.1701 - val_loss: 2.0981 - val_acc: 0.1870\n",
      "Epoch 100/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1454 - acc: 0.1740 - val_loss: 2.0989 - val_acc: 0.1910\n",
      "Epoch 101/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1463 - acc: 0.1712 - val_loss: 2.1007 - val_acc: 0.1917\n",
      "Epoch 102/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1611 - acc: 0.1746 - val_loss: 2.1484 - val_acc: 0.1481\n",
      "Epoch 103/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1435 - acc: 0.1758 - val_loss: 2.1394 - val_acc: 0.1565\n",
      "Epoch 104/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1521 - acc: 0.1724 - val_loss: 2.1317 - val_acc: 0.1568\n",
      "Epoch 105/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1525 - acc: 0.1766 - val_loss: 2.1381 - val_acc: 0.1651\n",
      "Epoch 106/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1602 - acc: 0.1655 - val_loss: 2.3000 - val_acc: 0.1485\n",
      "Epoch 107/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1552 - acc: 0.1730 - val_loss: 2.1314 - val_acc: 0.1861\n",
      "Epoch 108/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1663 - acc: 0.1737 - val_loss: 2.1438 - val_acc: 0.1914\n",
      "Epoch 109/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1384 - acc: 0.1751 - val_loss: 2.1294 - val_acc: 0.1475\n",
      "Epoch 110/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1438 - acc: 0.1724 - val_loss: 2.1704 - val_acc: 0.1904\n",
      "Epoch 111/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1426 - acc: 0.1675 - val_loss: 2.1718 - val_acc: 0.1821 lo\n",
      "Epoch 112/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1541 - acc: 0.1659 - val_loss: 2.1404 - val_acc: 0.1738\n",
      "Epoch 113/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1401 - acc: 0.1755 - val_loss: 2.1607 - val_acc: 0.1917\n",
      "Epoch 114/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1504 - acc: 0.1730 - val_loss: 2.1818 - val_acc: 0.1651\n",
      "Epoch 115/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1537 - acc: 0.1749 - val_loss: 2.1237 - val_acc: 0.1867\n",
      "Epoch 116/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1464 - acc: 0.1733 - val_loss: 2.1691 - val_acc: 0.1565\n",
      "Epoch 117/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1426 - acc: 0.1712 - val_loss: 2.1410 - val_acc: 0.1870\n",
      "Epoch 118/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1658 - acc: 0.1736 - val_loss: 2.2513 - val_acc: 0.1620\n",
      "Epoch 119/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1439 - acc: 0.1703 - val_loss: 2.1801 - val_acc: 0.1463\n",
      "Epoch 120/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1520 - acc: 0.1747 - val_loss: 2.1935 - val_acc: 0.1873\n",
      "Epoch 121/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1450 - acc: 0.1700 - val_loss: 2.1307 - val_acc: 0.1880\n",
      "Epoch 122/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1672 - acc: 0.1703 - val_loss: 2.1819 - val_acc: 0.1472\n",
      "Epoch 123/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1636 - acc: 0.1725 - val_loss: 2.1922 - val_acc: 0.1562\n",
      "Epoch 124/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1438 - acc: 0.1717 - val_loss: 2.1655 - val_acc: 0.1741\n",
      "Epoch 125/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1528 - acc: 0.1716 - val_loss: 2.1656 - val_acc: 0.1571\n",
      "Epoch 126/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1720 - acc: 0.1651 - val_loss: 2.0939 - val_acc: 0.1750\n",
      "Epoch 127/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7594/7594 [==============================] - 3s - loss: 2.1464 - acc: 0.1736 - val_loss: 2.2062 - val_acc: 0.1580\n",
      "Epoch 128/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1416 - acc: 0.1799 - val_loss: 2.2363 - val_acc: 0.1562\n",
      "Epoch 129/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1359 - acc: 0.1712 - val_loss: 2.1962 - val_acc: 0.1472\n",
      "Epoch 130/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1407 - acc: 0.1655 - val_loss: 2.1759 - val_acc: 0.1917\n",
      "Epoch 131/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1646 - acc: 0.1701 - val_loss: 2.1699 - val_acc: 0.1503\n",
      "Epoch 132/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1579 - acc: 0.1682 - val_loss: 2.1358 - val_acc: 0.1593\n",
      "Epoch 133/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1768 - acc: 0.1643 - val_loss: 2.2322 - val_acc: 0.1472\n",
      "Epoch 134/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1503 - acc: 0.1767 - val_loss: 2.1322 - val_acc: 0.1917\n",
      "Epoch 135/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1414 - acc: 0.1805 - val_loss: 2.1562 - val_acc: 0.1469\n",
      "Epoch 136/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1476 - acc: 0.1729 - val_loss: 2.1577 - val_acc: 0.1880\n",
      "Epoch 137/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1649 - acc: 0.1695 - val_loss: 2.1132 - val_acc: 0.1914\n",
      "Epoch 138/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1350 - acc: 0.1742 - val_loss: 2.1074 - val_acc: 0.1864\n",
      "Epoch 139/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1400 - acc: 0.1713 - val_loss: 2.1280 - val_acc: 0.1642\n",
      "Epoch 140/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1591 - acc: 0.1730 - val_loss: 2.1836 - val_acc: 0.1929\n",
      "Epoch 141/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1599 - acc: 0.1705 - val_loss: 2.1016 - val_acc: 0.1660\n",
      "Epoch 142/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1413 - acc: 0.1675 - val_loss: 2.2594 - val_acc: 0.1664\n",
      "Epoch 143/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1668 - acc: 0.1730 - val_loss: 2.1823 - val_acc: 0.1731\n",
      "Epoch 144/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1571 - acc: 0.1747 - val_loss: 2.1150 - val_acc: 0.1741\n",
      "Epoch 145/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1632 - acc: 0.1720 - val_loss: 2.1279 - val_acc: 0.1741\n",
      "Epoch 146/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1575 - acc: 0.1740 - val_loss: 2.1720 - val_acc: 0.1741\n",
      "Epoch 147/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1464 - acc: 0.1721 - val_loss: 2.1104 - val_acc: 0.1571\n",
      "Epoch 148/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1545 - acc: 0.1742 - val_loss: 2.1911 - val_acc: 0.1725\n",
      "Epoch 149/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1496 - acc: 0.1732 - val_loss: 2.2014 - val_acc: 0.1886\n",
      "Epoch 150/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1635 - acc: 0.1696 - val_loss: 2.1522 - val_acc: 0.1596\n",
      "Epoch 151/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1374 - acc: 0.1751 - val_loss: 2.1369 - val_acc: 0.1475\n",
      "Epoch 152/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1652 - acc: 0.1732 - val_loss: 2.1576 - val_acc: 0.1917\n",
      "Epoch 153/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1614 - acc: 0.1724 - val_loss: 2.1556 - val_acc: 0.1660\n",
      "Epoch 154/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1589 - acc: 0.1697 - val_loss: 2.1169 - val_acc: 0.1802\n",
      "Epoch 155/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1454 - acc: 0.1772 - val_loss: 2.1324 - val_acc: 0.1917\n",
      "Epoch 156/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1469 - acc: 0.1780 - val_loss: 2.1122 - val_acc: 0.1556\n",
      "Epoch 157/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1586 - acc: 0.1629 - val_loss: 2.1935 - val_acc: 0.1556\n",
      "Epoch 158/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1617 - acc: 0.1761 - val_loss: 2.2777 - val_acc: 0.1867\n",
      "Epoch 159/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1632 - acc: 0.1726 - val_loss: 2.1559 - val_acc: 0.1753\n",
      "Epoch 160/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1487 - acc: 0.1722 - val_loss: 2.1889 - val_acc: 0.1657\n",
      "Epoch 161/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1638 - acc: 0.1733 - val_loss: 2.1851 - val_acc: 0.1914\n",
      "Epoch 162/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1453 - acc: 0.1688 - val_loss: 2.1701 - val_acc: 0.1923\n",
      "Epoch 163/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1589 - acc: 0.1728 - val_loss: 2.1266 - val_acc: 0.1873\n",
      "Epoch 164/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1510 - acc: 0.1728 - val_loss: 2.1615 - val_acc: 0.1506\n",
      "Epoch 165/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1611 - acc: 0.1708 - val_loss: 2.1533 - val_acc: 0.1920\n",
      "Epoch 166/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1527 - acc: 0.1650 - val_loss: 2.1601 - val_acc: 0.1910\n",
      "Epoch 167/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1529 - acc: 0.1722 - val_loss: 2.1623 - val_acc: 0.1568\n",
      "Epoch 168/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1471 - acc: 0.1742 - val_loss: 2.1989 - val_acc: 0.1840\n",
      "Epoch 169/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1243 - acc: 0.1758 - val_loss: 2.1442 - val_acc: 0.1701\n",
      "Epoch 170/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1710 - acc: 0.1738 - val_loss: 2.1793 - val_acc: 0.1654\n",
      "Epoch 171/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1659 - acc: 0.1649 - val_loss: 2.1062 - val_acc: 0.1741\n",
      "Epoch 172/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1523 - acc: 0.1743 - val_loss: 2.1503 - val_acc: 0.1472\n",
      "Epoch 173/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1518 - acc: 0.1704 - val_loss: 2.1981 - val_acc: 0.1824\n",
      "Epoch 174/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1489 - acc: 0.1671 - val_loss: 2.1737 - val_acc: 0.1475\n",
      "Epoch 175/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1380 - acc: 0.1617 - val_loss: 2.1470 - val_acc: 0.1571\n",
      "Epoch 176/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1597 - acc: 0.1722 - val_loss: 2.1129 - val_acc: 0.1648\n",
      "Epoch 177/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1486 - acc: 0.1783 - val_loss: 2.3645 - val_acc: 0.1485\n",
      "Epoch 178/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1557 - acc: 0.1662 - val_loss: 2.2827 - val_acc: 0.1870\n",
      "Epoch 179/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1467 - acc: 0.1699 - val_loss: 2.1552 - val_acc: 0.1917\n",
      "Epoch 180/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1627 - acc: 0.1653 - val_loss: 2.1934 - val_acc: 0.1873\n",
      "Epoch 181/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1773 - acc: 0.1742 - val_loss: 2.1125 - val_acc: 0.1926\n",
      "Epoch 182/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1469 - acc: 0.1657 - val_loss: 2.1343 - val_acc: 0.1673\n",
      "Epoch 183/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1444 - acc: 0.1696 - val_loss: 2.1791 - val_acc: 0.1574\n",
      "Epoch 184/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1491 - acc: 0.1688 - val_loss: 2.1369 - val_acc: 0.1923\n",
      "Epoch 185/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1281 - acc: 0.1800 - val_loss: 2.1149 - val_acc: 0.1877\n",
      "Epoch 186/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1475 - acc: 0.1713 - val_loss: 2.1160 - val_acc: 0.1654\n",
      "Epoch 187/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1408 - acc: 0.1692 - val_loss: 2.1096 - val_acc: 0.1926\n",
      "Epoch 188/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1480 - acc: 0.1701 - val_loss: 2.1241 - val_acc: 0.1935\n",
      "Epoch 189/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1647 - acc: 0.1709 - val_loss: 2.1317 - val_acc: 0.1494\n",
      "Epoch 190/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7594/7594 [==============================] - 3s - loss: 2.1457 - acc: 0.1712 - val_loss: 2.1264 - val_acc: 0.1750\n",
      "Epoch 191/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1564 - acc: 0.1726 - val_loss: 2.1178 - val_acc: 0.1935\n",
      "Epoch 192/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1352 - acc: 0.1755 - val_loss: 2.1272 - val_acc: 0.1877\n",
      "Epoch 193/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1474 - acc: 0.1704 - val_loss: 2.1694 - val_acc: 0.1475\n",
      "Epoch 194/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1616 - acc: 0.1774 - val_loss: 2.1286 - val_acc: 0.1722\n",
      "Epoch 195/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1516 - acc: 0.1705 - val_loss: 2.1437 - val_acc: 0.1654\n",
      "Epoch 196/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1376 - acc: 0.1804 - val_loss: 2.1247 - val_acc: 0.1747\n",
      "Epoch 197/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1453 - acc: 0.1763 - val_loss: 2.1442 - val_acc: 0.1568\n",
      "Epoch 198/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1372 - acc: 0.1746 - val_loss: 2.1217 - val_acc: 0.1799\n",
      "Epoch 199/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1601 - acc: 0.1747 - val_loss: 2.1834 - val_acc: 0.1920\n",
      "Epoch 200/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1743 - acc: 0.1668 - val_loss: 2.1658 - val_acc: 0.1488\n",
      "Epoch 201/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1527 - acc: 0.1726 - val_loss: 2.1530 - val_acc: 0.1735\n",
      "Epoch 202/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1679 - acc: 0.1693 - val_loss: 2.1256 - val_acc: 0.1870\n",
      "Epoch 203/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1522 - acc: 0.1759 - val_loss: 2.1724 - val_acc: 0.1920\n",
      "Epoch 204/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1329 - acc: 0.1701 - val_loss: 2.1235 - val_acc: 0.1574\n",
      "Epoch 205/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1511 - acc: 0.1729 - val_loss: 2.1939 - val_acc: 0.1873\n",
      "Epoch 206/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1542 - acc: 0.1750 - val_loss: 2.1141 - val_acc: 0.1660\n",
      "Epoch 207/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1437 - acc: 0.1751 - val_loss: 2.1816 - val_acc: 0.1648\n",
      "Epoch 208/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1444 - acc: 0.1728 - val_loss: 2.2309 - val_acc: 0.1849\n",
      "Epoch 209/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1607 - acc: 0.1758 - val_loss: 2.1543 - val_acc: 0.1870\n",
      "Epoch 210/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1511 - acc: 0.1670 - val_loss: 2.1723 - val_acc: 0.1892\n",
      "Epoch 211/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1694 - acc: 0.1713 - val_loss: 2.1732 - val_acc: 0.1568\n",
      "Epoch 212/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1397 - acc: 0.1683 - val_loss: 2.1493 - val_acc: 0.1660\n",
      "Epoch 213/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1405 - acc: 0.1747 - val_loss: 2.2167 - val_acc: 0.1475\n",
      "Epoch 214/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1331 - acc: 0.1730 - val_loss: 2.1671 - val_acc: 0.1475\n",
      "Epoch 215/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1674 - acc: 0.1716 - val_loss: 2.1879 - val_acc: 0.1481\n",
      "Epoch 216/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1371 - acc: 0.1755 - val_loss: 2.1376 - val_acc: 0.1914\n",
      "Epoch 217/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1386 - acc: 0.1786 - val_loss: 2.1354 - val_acc: 0.1880\n",
      "Epoch 218/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1371 - acc: 0.1790 - val_loss: 2.1597 - val_acc: 0.1657\n",
      "Epoch 219/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1371 - acc: 0.1776 - val_loss: 2.1845 - val_acc: 0.1160\n",
      "Epoch 220/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1547 - acc: 0.1709 - val_loss: 2.1675 - val_acc: 0.1735\n",
      "Epoch 221/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1538 - acc: 0.1688 - val_loss: 2.1361 - val_acc: 0.1670\n",
      "Epoch 222/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1491 - acc: 0.1796 - val_loss: 2.1113 - val_acc: 0.1735\n",
      "Epoch 223/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1460 - acc: 0.1689 - val_loss: 2.1388 - val_acc: 0.1753\n",
      "Epoch 224/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1462 - acc: 0.1799 - val_loss: 2.1277 - val_acc: 0.1926\n",
      "Epoch 225/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1401 - acc: 0.1730 - val_loss: 2.1513 - val_acc: 0.1895\n",
      "Epoch 226/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1429 - acc: 0.1741 - val_loss: 2.2013 - val_acc: 0.1657\n",
      "Epoch 227/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1582 - acc: 0.1787 - val_loss: 2.1675 - val_acc: 0.1519\n",
      "Epoch 228/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1240 - acc: 0.1820 - val_loss: 2.1924 - val_acc: 0.1642\n",
      "Epoch 229/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1718 - acc: 0.1658 - val_loss: 2.2025 - val_acc: 0.1571\n",
      "Epoch 230/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1673 - acc: 0.1738 - val_loss: 2.1981 - val_acc: 0.1870\n",
      "Epoch 231/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1410 - acc: 0.1775 - val_loss: 2.1894 - val_acc: 0.1802\n",
      "Epoch 232/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1419 - acc: 0.1717 - val_loss: 2.1167 - val_acc: 0.1750\n",
      "Epoch 233/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1444 - acc: 0.1684 - val_loss: 2.1524 - val_acc: 0.17500.16\n",
      "Epoch 234/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1496 - acc: 0.1663 - val_loss: 2.1714 - val_acc: 0.1648\n",
      "Epoch 235/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1383 - acc: 0.1746 - val_loss: 2.1594 - val_acc: 0.1478\n",
      "Epoch 236/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1479 - acc: 0.1725 - val_loss: 2.1564 - val_acc: 0.1299\n",
      "Epoch 237/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1341 - acc: 0.1753 - val_loss: 2.1939 - val_acc: 0.1472\n",
      "Epoch 238/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1558 - acc: 0.1770 - val_loss: 2.1558 - val_acc: 0.1593\n",
      "Epoch 239/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1467 - acc: 0.1676 - val_loss: 2.1182 - val_acc: 0.1935\n",
      "Epoch 240/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1603 - acc: 0.1682 - val_loss: 2.1091 - val_acc: 0.1929\n",
      "Epoch 241/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1527 - acc: 0.1734 - val_loss: 2.1284 - val_acc: 0.1867\n",
      "Epoch 242/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1402 - acc: 0.1736 - val_loss: 2.1527 - val_acc: 0.1562\n",
      "Epoch 243/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1478 - acc: 0.1704 - val_loss: 2.1824 - val_acc: 0.1660\n",
      "Epoch 244/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1606 - acc: 0.1782 - val_loss: 2.2136 - val_acc: 0.1920\n",
      "Epoch 245/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1356 - acc: 0.1813 - val_loss: 2.1268 - val_acc: 0.1880\n",
      "Epoch 246/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1372 - acc: 0.1733 - val_loss: 2.2082 - val_acc: 0.1586\n",
      "Epoch 247/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1446 - acc: 0.1771 - val_loss: 2.1429 - val_acc: 0.1750\n",
      "Epoch 248/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1648 - acc: 0.1712 - val_loss: 2.1176 - val_acc: 0.1799\n",
      "Epoch 249/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1535 - acc: 0.1736 - val_loss: 2.1522 - val_acc: 0.1475\n",
      "Epoch 250/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1633 - acc: 0.1718 - val_loss: 2.1494 - val_acc: 0.1648\n",
      "Epoch 251/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1551 - acc: 0.1699 - val_loss: 2.1192 - val_acc: 0.1472\n",
      "Epoch 252/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1347 - acc: 0.1819 - val_loss: 2.1270 - val_acc: 0.1750\n",
      "Epoch 253/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7594/7594 [==============================] - 3s - loss: 2.1334 - acc: 0.1708 - val_loss: 2.2344 - val_acc: 0.1870\n",
      "Epoch 254/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1500 - acc: 0.1779 - val_loss: 2.1820 - val_acc: 0.1873\n",
      "Epoch 255/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1573 - acc: 0.1701 - val_loss: 2.1459 - val_acc: 0.18890.170\n",
      "Epoch 256/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1491 - acc: 0.1759 - val_loss: 2.1502 - val_acc: 0.1889\n",
      "Epoch 257/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1578 - acc: 0.1678 - val_loss: 2.2077 - val_acc: 0.1577\n",
      "Epoch 258/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1613 - acc: 0.1625 - val_loss: 2.1303 - val_acc: 0.1926\n",
      "Epoch 259/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1535 - acc: 0.1787 - val_loss: 2.1972 - val_acc: 0.1571\n",
      "Epoch 260/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1663 - acc: 0.1753 - val_loss: 2.1895 - val_acc: 0.14750.175\n",
      "Epoch 261/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1543 - acc: 0.1708 - val_loss: 2.1521 - val_acc: 0.1568\n",
      "Epoch 262/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1566 - acc: 0.1671 - val_loss: 2.1971 - val_acc: 0.1753\n",
      "Epoch 263/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1539 - acc: 0.1668 - val_loss: 2.1170 - val_acc: 0.1880\n",
      "Epoch 264/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1698 - acc: 0.1817 - val_loss: 2.1119 - val_acc: 0.1926\n",
      "Epoch 265/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1443 - acc: 0.1672 - val_loss: 2.1701 - val_acc: 0.1929\n",
      "Epoch 266/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1613 - acc: 0.1736 - val_loss: 2.1773 - val_acc: 0.1657\n",
      "Epoch 267/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1556 - acc: 0.1753 - val_loss: 2.1817 - val_acc: 0.1867\n",
      "Epoch 268/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1500 - acc: 0.1670 - val_loss: 2.1437 - val_acc: 0.1926\n",
      "Epoch 269/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1290 - acc: 0.1772 - val_loss: 2.1720 - val_acc: 0.1750\n",
      "Epoch 270/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1580 - acc: 0.1717 - val_loss: 2.1890 - val_acc: 0.18700.\n",
      "Epoch 271/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1444 - acc: 0.1703 - val_loss: 2.1445 - val_acc: 0.1920\n",
      "Epoch 272/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1633 - acc: 0.1730 - val_loss: 2.1635 - val_acc: 0.1741\n",
      "Epoch 273/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1464 - acc: 0.1791 - val_loss: 2.1251 - val_acc: 0.1880\n",
      "Epoch 274/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1493 - acc: 0.1696 - val_loss: 2.1860 - val_acc: 0.1923\n",
      "Epoch 275/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1512 - acc: 0.1687 - val_loss: 2.1408 - val_acc: 0.1849\n",
      "Epoch 276/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1517 - acc: 0.1728 - val_loss: 2.1014 - val_acc: 0.1926\n",
      "Epoch 277/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1614 - acc: 0.1709 - val_loss: 2.1471 - val_acc: 0.1664\n",
      "Epoch 278/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1546 - acc: 0.1676 - val_loss: 2.1247 - val_acc: 0.1914\n",
      "Epoch 279/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1441 - acc: 0.1730 - val_loss: 2.1385 - val_acc: 0.1796\n",
      "Epoch 280/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1555 - acc: 0.1663 - val_loss: 2.1717 - val_acc: 0.1926\n",
      "Epoch 281/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1454 - acc: 0.1740 - val_loss: 2.1388 - val_acc: 0.1731\n",
      "Epoch 282/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1313 - acc: 0.1769 - val_loss: 2.1122 - val_acc: 0.1562\n",
      "Epoch 283/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1547 - acc: 0.1659 - val_loss: 2.1484 - val_acc: 0.1472\n",
      "Epoch 284/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1459 - acc: 0.1755 - val_loss: 2.1719 - val_acc: 0.1645\n",
      "Epoch 285/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1711 - acc: 0.1733 - val_loss: 2.2267 - val_acc: 0.1753\n",
      "Epoch 286/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1559 - acc: 0.1724 - val_loss: 2.1850 - val_acc: 0.1654\n",
      "Epoch 287/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1596 - acc: 0.1707 - val_loss: 2.2640 - val_acc: 0.1920\n",
      "Epoch 288/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1638 - acc: 0.1712 - val_loss: 2.1890 - val_acc: 0.1583\n",
      "Epoch 289/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1681 - acc: 0.1659 - val_loss: 2.1419 - val_acc: 0.1929\n",
      "Epoch 290/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1341 - acc: 0.1724 - val_loss: 2.1080 - val_acc: 0.1574\n",
      "Epoch 291/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1711 - acc: 0.1693 - val_loss: 2.1576 - val_acc: 0.1741\n",
      "Epoch 292/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1305 - acc: 0.1774 - val_loss: 2.1504 - val_acc: 0.1664\n",
      "Epoch 293/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1473 - acc: 0.1754 - val_loss: 2.1835 - val_acc: 0.1509\n",
      "Epoch 294/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1489 - acc: 0.1772 - val_loss: 2.1996 - val_acc: 0.1932\n",
      "Epoch 295/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1548 - acc: 0.1738 - val_loss: 2.2341 - val_acc: 0.1867\n",
      "Epoch 296/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1524 - acc: 0.1703 - val_loss: 2.1553 - val_acc: 0.1877\n",
      "Epoch 297/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1275 - acc: 0.1751 - val_loss: 2.1180 - val_acc: 0.1926\n",
      "Epoch 298/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1446 - acc: 0.1725 - val_loss: 2.1428 - val_acc: 0.1722\n",
      "Epoch 299/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1336 - acc: 0.1689 - val_loss: 2.2775 - val_acc: 0.1562\n",
      "Epoch 300/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1677 - acc: 0.1691 - val_loss: 2.1268 - val_acc: 0.1738\n",
      "Epoch 301/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1394 - acc: 0.1717 - val_loss: 2.1303 - val_acc: 0.1929\n",
      "Epoch 302/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1634 - acc: 0.1711 - val_loss: 2.2660 - val_acc: 0.1469\n",
      "Epoch 303/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1744 - acc: 0.1740 - val_loss: 2.3019 - val_acc: 0.1552\n",
      "Epoch 304/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1559 - acc: 0.1730 - val_loss: 2.2033 - val_acc: 0.1574\n",
      "Epoch 305/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1673 - acc: 0.1717 - val_loss: 2.1364 - val_acc: 0.1562\n",
      "Epoch 306/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1680 - acc: 0.1667 - val_loss: 2.1283 - val_acc: 0.1923\n",
      "Epoch 307/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1399 - acc: 0.1674 - val_loss: 2.1586 - val_acc: 0.1914\n",
      "Epoch 308/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1437 - acc: 0.1733 - val_loss: 2.1603 - val_acc: 0.1735\n",
      "Epoch 309/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1520 - acc: 0.1728 - val_loss: 2.2192 - val_acc: 0.1864\n",
      "Epoch 310/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1474 - acc: 0.1718 - val_loss: 2.2000 - val_acc: 0.1562\n",
      "Epoch 311/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1468 - acc: 0.1734 - val_loss: 2.1566 - val_acc: 0.1731\n",
      "Epoch 312/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1470 - acc: 0.1692 - val_loss: 2.1455 - val_acc: 0.1929\n",
      "Epoch 313/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1581 - acc: 0.1670 - val_loss: 2.3091 - val_acc: 0.1799\n",
      "Epoch 314/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1532 - acc: 0.1703 - val_loss: 2.1896 - val_acc: 0.1843\n",
      "Epoch 315/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1511 - acc: 0.1751 - val_loss: 2.2297 - val_acc: 0.1929\n",
      "Epoch 316/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7594/7594 [==============================] - 3s - loss: 2.1634 - acc: 0.1763 - val_loss: 2.1506 - val_acc: 0.1660\n",
      "Epoch 317/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1491 - acc: 0.1742 - val_loss: 2.1658 - val_acc: 0.1929\n",
      "Epoch 318/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1483 - acc: 0.1708 - val_loss: 2.1384 - val_acc: 0.1361\n",
      "Epoch 319/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1545 - acc: 0.1716 - val_loss: 2.1572 - val_acc: 0.1877\n",
      "Epoch 320/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1488 - acc: 0.1738 - val_loss: 2.1590 - val_acc: 0.1568\n",
      "Epoch 321/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1345 - acc: 0.1663 - val_loss: 2.1395 - val_acc: 0.1657\n",
      "Epoch 322/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1256 - acc: 0.1754 - val_loss: 2.1468 - val_acc: 0.1883\n",
      "Epoch 323/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1457 - acc: 0.1724 - val_loss: 2.1389 - val_acc: 0.1590\n",
      "Epoch 324/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1408 - acc: 0.1743 - val_loss: 2.1818 - val_acc: 0.1880\n",
      "Epoch 325/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1570 - acc: 0.1658 - val_loss: 2.2021 - val_acc: 0.1873\n",
      "Epoch 326/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1701 - acc: 0.1697 - val_loss: 2.1062 - val_acc: 0.1660\n",
      "Epoch 327/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1571 - acc: 0.1724 - val_loss: 2.0977 - val_acc: 0.1914\n",
      "Epoch 328/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1560 - acc: 0.1687 - val_loss: 2.1705 - val_acc: 0.1664\n",
      "Epoch 329/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1484 - acc: 0.1733 - val_loss: 2.1268 - val_acc: 0.1735\n",
      "Epoch 330/2000\n",
      "7594/7594 [==============================] - 3s - loss: 2.1526 - acc: 0.1697 - val_loss: 2.1687 - val_acc: 0.1873\n",
      "Epoch 331/2000\n",
      "6350/7594 [========================>.....] - ETA: 0s - loss: 2.1398 - acc: 0.172 - ETA: 0s - loss: 2.1416 - acc: 0.1715"
     ]
    }
   ],
   "source": [
    "model.fit(train_x, train_y,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              validation_data=(test_x, test_y),\n",
    "              shuffle=True,\n",
    "              callbacks=[csv_logger])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
